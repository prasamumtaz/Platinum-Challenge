{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b030a3d9-4989-402e-a91f-9f22ca0f14b6",
   "metadata": {},
   "source": [
    "# Import, Clean, Drop Duplicate from Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49b85991-7087-4c0f-85a5-b6777849aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78885a17-1bb9-40fb-a062-633d66e1884e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
       "1  mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
       "2  lokasi strategis di jalan sumatera bandung . t...  positive\n",
       "3  betapa bahagia nya diri ini saat unboxing pake...  positive\n",
       "4  duh . jadi mahasiswa jangan sombong dong . kas...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_table(r\"E:\\BINAR\\Platinum-Challenge\\Dataset\\train_preprocess.tsv.txt\", sep='\\t', header=None)\n",
    "df_train = df_train.rename(columns={0: 'text', 1: 'label'})\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63eca449-d461-4b6b-afd3-2ca3ca3ffbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd3651b4-161d-489b-af42-3fb1659e7efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c098ecfc-7780-4694-b4f5-d47d798e5452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11000 entries, 0 to 10999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    11000 non-null  object\n",
      " 1   label   11000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 172.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418f1baa-9f55-4265-87b8-84cb365bcf9b",
   "metadata": {},
   "source": [
    "## Cek duplikat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8079257-a4ca-4f07-86bc-cf0b6a24e418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#duplicate check\n",
    "df_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88c13e59-8043-4384-934e-6694fd2966a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicate\n",
    "df_train = df_train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef2fc7e-6eb5-411a-8f28-69727ff20a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindex\n",
    "df_train = df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd4f66c5-5fa4-46e9-8178-b761506c2460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#duplicate check\n",
    "df_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1390977a-3395-4d36-97a7-9acb874b53da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10933 entries, 0 to 10999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    10933 non-null  object\n",
      " 1   label   10933 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 256.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b38c5550-c7f0-4cc9-9732-bf400333712d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10933, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d02cf0d-c5ae-4698-adec-7fa3cb5ced7a",
   "metadata": {},
   "source": [
    "## Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e67d680f-ecf7-4120-9cf1-762d3826be26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords as stopword_scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f05fa70-e332-4516-944e-aec71d729c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fucntion to Clean tweet data\n",
    "def Clean(text):\n",
    "    #lowercase for every word\n",
    "    text = text.lower()\n",
    "\n",
    "    #Clean Pattern\n",
    "    #remove USER\n",
    "    text = re.sub(r'user', ' ', text)\n",
    "    #remove 'RT'\n",
    "    text = re.sub(r'rt', ' ', text)\n",
    "    #remove 'URL'\n",
    "    text = re.sub(r'url', ' ', text)\n",
    "    #remove HTTPS\n",
    "    text = re.sub(r'https', ' ', text)\n",
    "    #remove HTTP\n",
    "    text = re.sub(r'http', ' ', text)\n",
    "    #remove &amp\n",
    "    text = re.sub(r'&amp', ' ', text)\n",
    "\n",
    "    #Clean_Unnecessary_Character\n",
    "    #remove \\n or every word afte '\\' with space\n",
    "    text = re.sub(r'\\\\+[a-zA-Z0-9]+', ' ', text)\n",
    "    #remove text emoji\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]{2,}|:[a-zA-Z0-9]{0,}', ' ', text)\n",
    "    #remove all unnecessary character \n",
    "    text = re.sub(r'[^0-9a-zA-Z\\s]+', ' ', text)\n",
    "    #remove all number\n",
    "    text = re.sub(r'[0-9]+', ' ', text)\n",
    "    #remove extra space\n",
    "    text = re.sub(r'  +', ' ', text)\n",
    "    #remove space at the start or the end of string\n",
    "    text = re.sub(r'^ +| +$', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "#tokenization Function\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "#import file new_kamusalay.csv\n",
    "kamus_alay = pd.read_csv(r\"E:\\BINAR\\Binar-Gold-Challenge\\Dataset\\new_kamusalay.csv\", encoding = 'ISO-8859-1', header = None)\n",
    "kamus_alay = kamus_alay.rename(columns={0: 'kata alay', 1: 'arti kata'})\n",
    "\n",
    "#Create dictionary from kamus_alay\n",
    "kamus_alay_dict = dict(zip(kamus_alay['kata alay'], kamus_alay['arti kata']))\n",
    "\n",
    "#normalization function to convert every word tha contain 'kata alay' to 'arti kata'\n",
    "def normalization(text):\n",
    "    newlist = []\n",
    "    for word in text:\n",
    "        if word in kamus_alay_dict:\n",
    "            text = kamus_alay_dict[word]\n",
    "            newlist.append(text)\n",
    "        else:\n",
    "            text = word\n",
    "            newlist.append(text)\n",
    "    return newlist\n",
    "\n",
    "#remove stopwords\n",
    "\n",
    "#list stopword from NLTK\n",
    "list_stopwords = stopword_scratch.words('indonesian')\n",
    "list_stopwords_en = stopword_scratch.words('english')\n",
    "list_stopwords.extend(list_stopwords_en)\n",
    "list_stopwords.extend(['ya', 'yg', 'ga', 'yuk', 'dah'])\n",
    "stopword_list = list_stopwords\n",
    "\n",
    "#stopword list\n",
    "f = open(r\"E:\\BINAR\\Binar-Gold-Challenge\\Dataset\\tala-stopwords-indonesia.txt\")\n",
    "stopword_list = []\n",
    "for line in f:\n",
    "    stripped_line = line.strip()\n",
    "    line_list = stripped_line.split()\n",
    "    stopword_list.append(line_list[0])\n",
    "f.close()\n",
    "\n",
    "stopword_list.extend([\"yg\", \"dg\", \"rt\", \"dgn\", \"ny\", \"d\", 'klo',\n",
    "                       'kalo', 'amp', 'biar', 'bikin', 'bilang',\n",
    "                       'gak', 'ga', 'krn', 'nya', 'nih', 'sih',\n",
    "                       'si', 'tau', 'tdk', 'tuh', 'utk', 'ya',\n",
    "                       'jd', 'jgn', 'sdh', 'aja', 'n', 't',\n",
    "                       'nyg', 'hehe', 'pen', 'u', 'nan', 'loh', 'rt',\n",
    "                       'gue', 'yah', 'kayak'])\n",
    "\n",
    "stopword_list = set(stopword_list)\n",
    "\n",
    "#remove stopword function\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword_list]\n",
    "    return text\n",
    "\n",
    "#function to run all the function\n",
    "def clean_data(text):\n",
    "    text = Clean(text)\n",
    "    text = tokenization(text)\n",
    "    text = normalization(text)\n",
    "    text = remove_stopwords(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1293bdc6-a654-4675-a9d6-6112d559fe4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>warung dimiliki pengusaha pabrik puluhan terke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mohon ulama lurus k mmbri hujjah ai diwlh suar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>lokasi strategis jalan sumatra bandung nyaman ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "      <td>betapa bahagia unboxing paket barang bagus men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "      <td>aduh mahasiswa sombong kasih kakak kuning bela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label  \\\n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...  positive   \n",
       "1  mohon ulama lurus dan k212 mmbri hujjah partai...   neutral   \n",
       "2  lokasi strategis di jalan sumatera bandung . t...  positive   \n",
       "3  betapa bahagia nya diri ini saat unboxing pake...  positive   \n",
       "4  duh . jadi mahasiswa jangan sombong dong . kas...  negative   \n",
       "\n",
       "                                          text_clean  \n",
       "0  warung dimiliki pengusaha pabrik puluhan terke...  \n",
       "1  mohon ulama lurus k mmbri hujjah ai diwlh suar...  \n",
       "2  lokasi strategis jalan sumatra bandung nyaman ...  \n",
       "3  betapa bahagia unboxing paket barang bagus men...  \n",
       "4  aduh mahasiswa sombong kasih kakak kuning bela...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['text_clean'] = df_train.text.apply(lambda x: ' '.join(map(str, clean_data(x))))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6adaf0b0-8067-4b8a-9fcd-067a86d38bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10933 entries, 0 to 10999\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        10933 non-null  object\n",
      " 1   label       10933 non-null  object\n",
      " 2   text_clean  10933 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 341.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597aba3e-a89a-40b2-8f1f-9a8b8e7eb8ec",
   "metadata": {},
   "source": [
    "## Sort Data from Label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7f9f757-a037-44b3-b5bc-a11a222921a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = df_train.loc[df_train['label'] == 'negative'].text_clean.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb104f4-b6e3-4760-820b-95a27e8c750b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357cf41f-9a20-436a-9b2e-5e227527b4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a237f1-d65d-46c3-a570-44a002cc9333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35007e51-a98b-41a3-97b3-d631f34230bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67efe8d-b357-4d93-9d6e-58017080933f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279870c3-921e-4048-9114-1ab600c6eeb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b30ef-2614-404e-b068-10664d6099d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
